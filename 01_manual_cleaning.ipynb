{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Data Cleaning\n",
                "\n",
                "Dans ce notebook, nous allons nettoyer un dataset \"sale\" Ã  la main avec Pandas. \n",
                "\n",
                "**Objectifs pÃ©dagogiques :**\n",
                "1. DÃ©tecter les anomalies (Types, Doublons, Valeurs manquantes).\n",
                "2. Standardiser des formats hÃ©tÃ©rogÃ¨nes (Dates, Prix).\n",
                "3. Corriger les erreurs de saisie (Typos, Casses).\n",
                "4. Traiter les valeurs aberrantes (Outliers).\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Chargement et Exploration Initiale\n",
                "\n",
                "Avant de toucher aux donnÃ©es, il faut comprendre ce qu'on a entre les mains. \n",
                "`read_csv` est le point d'entrÃ©e classique. On utilise ensuite `info()` pour voir les types de donnÃ©es infÃ©rÃ©s par Pandas."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "# Chargement du dataset\n",
                "df = pd.read_csv('dirty_sales_data.csv')\n",
                "\n",
                "# AperÃ§u rapide\n",
                "display(df.head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ðŸ”Ž Analyse du problÃ¨me\n",
                "En regardant le rÃ©sultat de `df.info()`, on remarque plusieurs red flags :\n",
                "- **Date** est de type `object` (string) -> Il faudrait du `datetime`.\n",
                "- **Unit_Price** est de type `object` (string) -> Il y a probablement des symboles monÃ©taires.\n",
                "- **Quantity** est bien un `int`, mais nous devrons vÃ©rifier sa cohÃ©rence mÃ©tier."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Gestion des Doublons\n",
                "\n",
                "Les doublons polluent les analyses. Il y a deux types :\n",
                "1. **Doublons parfaits** : Toute la ligne est identique.\n",
                "2. **Doublons partiels** : MÃªme identifiant unique (`Transaction_ID`) mais donnÃ©es diffÃ©rentes (conflit).\n",
                "\n",
                "CommenÃ§ons par supprimer les doublons parfaits."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compter les doublons initiaux\n",
                "print(f\"Doublons : {df.duplicated().sum()}\")\n",
                "display(df[df.duplicated(keep=False)])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Suppression des doublons exacts\n",
                "df = df.drop_duplicates()\n",
                "print(f\"Doublons aprÃ¨s nettoyage : {df.duplicated().sum()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Maintenant, vÃ©rifions si des `Transaction_ID` se rÃ©pÃ¨tent encore (doublons logiques)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# VÃ©rification des IDs dupliquÃ©s\n",
                "duplicates_ids = df[df.duplicated(subset=['Transaction_ID'], keep=False)]\n",
                "print(f\"Nombre de lignes avec ID conflictuels : {len(duplicates_ids)}\")\n",
                "\n",
                "display(duplicates_ids.sort_values(by='Transaction_ID').head(10))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# StratÃ©gie : On garde la derniÃ¨re occurrence (rÃ¨gle mÃ©tier interne)\n",
                "# Sinon on ferait une investigation plus poussÃ©e (timestamp, etc.)\n",
                "df = df.drop_duplicates(subset=['Transaction_ID'], keep='last')\n",
                "df[df.duplicated(subset=['Transaction_ID'], keep=False)]\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Standardisation des Dates\n",
                "\n",
                "La colonne `Date` contient un mÃ©lange de formats (YYYY-MM-DD vs DD/MM/YYYY) et du texte poubelle.\n",
                "Utiliser simplement `pd.to_datetime(..., errors='coerce')` est risquÃ© car cela supprimerait les dates valides au format franÃ§ais (ex: 18/07/2025).\n",
                "\n",
                "**Solution Robuste :** Tenter plusieurs conversions successives.\n",
                "1. D'abord le format ISO (majoritaire).\n",
                "2. Ensuite le format EuropÃ©en sur les Ã©checs.\n",
                "3. Ne garder en erreur que ce qui Ã©choue aux deux."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# AperÃ§u du problÃ¨me\n",
                "print(\"Exemples de dates avant conversion :\")\n",
                "print(df['Date'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Tentative Format ISO (YYYY-MM-DD)\n",
                "dates_iso = pd.to_datetime(df['Date'], format='%Y-%m-%d', errors='coerce')\n",
                "dates_iso.head(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Tentative Format FR (DD/MM/YYYY) sur les lignes en Ã©chec (NaT)\n",
                "mask_missed = dates_iso.isna()\n",
                "dates_fr = pd.to_datetime(df.loc[mask_missed, 'Date'], format='%d/%m/%Y', errors='coerce')\n",
                "dates_fr.head(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Combinaison : On remplit les trous de l'ISO avec les succÃ¨s du FR\n",
                "df['Date'] = dates_iso.fillna(dates_fr)\n",
                "df.head(15)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Bilan\n",
                "saved_docs = dates_fr.notna().sum()\n",
                "final_missing = df['Date'].isnull().sum()\n",
                "print(f\"\\nDates rÃ©cupÃ©rÃ©es via format FR : {saved_docs}\")\n",
                "print(f\"Dates irrÃ©cupÃ©rables (Vraies poubelles) : {final_missing}\")\n",
                "\n",
                "# Suppression des lignes sans date valide, indispensables pour la suite de l'analyse\n",
                "df = df.dropna(subset=['Date'])\n",
                "df.head(10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Nettoyage des chaÃ®nes de caractÃ¨res (Strings)\n",
                "\n",
                "### A. Noms Clients\n",
                "Les noms ont des problÃ¨mes de casse (\"ACME\" vs \"Acme\") et des espaces superflus. \n",
                "Standardisons tout en \"Title Case\" et retirons les espaces."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df['Client_Name']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df['Client_Name'].str.strip()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df['Client_Name'].str.strip().str.title()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Nettoyage espaces + Title Case\n",
                "df['Client_Name'] = df['Client_Name'].str.strip().str.title()\n",
                "\n",
                "# VÃ©rification rapide\n",
                "print(df['Client_Name'].sample(5))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### B. CatÃ©gories Produits (Typos)\n",
                "Regardons les valeurs uniques pour repÃ©rer les fautes de frappe."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"valeurs uniques avant :\", df['Product_Category'].unique())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dictionnaire de correction\n",
                "corrections = {\n",
                "    'Sofware': 'Software', 'Softwar': 'Software', 'Softwaree': 'Software',\n",
                "    'Electornics': 'Electronics', 'Elec': 'Electronics', 'Electronic': 'Electronics',\n",
                "    'Clothng': 'Clothing', 'Clotting': 'Clothing',\n",
                "    'H0me': 'Home', 'Hom': 'Home',\n",
                "    'Boks': 'Books', 'Book': 'Books'\n",
                "}\n",
                "\n",
                "# Application (replace ou map)\n",
                "df['Product_Category'] = df['Product_Category'].replace(corrections)\n",
                "\n",
                "print(\"\\nValeurs uniques aprÃ¨s :\", df['Product_Category'].unique())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Conversions NumÃ©riques complexes (Prix)\n",
                "\n",
                "C'est souvent le plus dur. `Unit_Price` contient des \"$\", \"â‚¬\", \"USD\". \n",
                "Il faut :\n",
                "1. Identifier les symboles.\n",
                "2. GÃ©rer le format europÃ©en (1.200,50) vs US (1,200.50) si nÃ©cessaire.\n",
                "3. Convertir en float.\n",
                "\n",
                "*Pour simplifier ici, on va retirer tous les caractÃ¨res non numÃ©riques (sauf '.' et ',') et uniformiser.*"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df['Unit_Price'].head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\"$793 USD\".replace('$', '')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\"$793 USD \".replace('$', '').replace('USD', '').strip()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "p = \"1,000,000.73\"\n",
                "p = \"1.000.00,73\"\n",
                "p = \"10000,73\"\n",
                "if ',' in p and '.' in p:\n",
                "    if p.rfind(',') > p.rfind('.'):\n",
                "            # Format US 1,000.00 mais inversÃ© ?? Ou juste Europe 1.000,00\n",
                "            # On remplace . par rein, et , par .\n",
                "            p = p.replace('.', '').replace(',', '.')\n",
                "    else:\n",
                "            # Format US 1,000.00 -> remove ,\n",
                "            p = p.replace(',', '')\n",
                "elif ',' in p:\n",
                "    # Juste une virgule ? Probablement dÃ©cimale si pas de point\n",
                "    p = p.replace(',', '.')\n",
                "\n",
                "p"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def clean_price(price_str):\n",
                "    if isinstance(price_str, (int, float)):\n",
                "        return float(price_str)\n",
                "    \n",
                "    # Convertir en string propre\n",
                "    p = str(price_str)\n",
                "    \n",
                "    # Cas simple : on retire devises et espaces\n",
                "    p = p.replace('$', '').replace('â‚¬', '').replace('USD', '').strip()\n",
                "    \n",
                "    # Gestion format Europe (point pour millier, virgule pour dÃ©cimale)\n",
                "    # Heuristique simple : si ',' est le dernier sÃ©parateur, c'est une dÃ©cimale\n",
                "    if ',' in p and '.' in p:\n",
                "        if p.rfind(',') > p.rfind('.'):\n",
                "             # Format US 1,000.00 mais inversÃ© ?? Ou juste Europe 1.000,00\n",
                "             # On remplace . par rein, et , par .\n",
                "             p = p.replace('.', '').replace(',', '.')\n",
                "        else:\n",
                "             # Format US 1,000.00 -> remove ,\n",
                "             p = p.replace(',', '')\n",
                "    elif ',' in p:\n",
                "        # Juste une virgule ? Probablement dÃ©cimale si pas de point\n",
                "        p = p.replace(',', '.')\n",
                "    \n",
                "    return float(p)\n",
                "\n",
                "df['Unit_Price'] = df['Unit_Price'].apply(clean_price)\n",
                "display(df.head(10))\n",
                "print(df['Unit_Price'].describe())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Valeurs Aberrantes (Outliers)\n",
                "\n",
                "La colonne `Quantity` ne doit pas Ãªtre nÃ©gative, et 10,000 articles d'un coup, c'est suspect."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Avant nettoyage :\")\n",
                "print(df['Quantity'].describe())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# RÃ¨gles mÃ©tier :\n",
                "# 1. Quantity > 0\n",
                "# 2. Quantity < 100 (seuil arbitraire)\n",
                "\n",
                "condition_valide = (df['Quantity'] > 0) & (df['Quantity'] < 100)\n",
                "condition_valide\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_clean = df[condition_valide].copy()\n",
                "df_clean"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\nAprÃ¨s nettoyage :\")\n",
                "print(df_clean['Quantity'].describe())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion\n",
                "\n",
                "Nous avons converti un dataset \"sale\" en dataset propre prÃªt pour l'analyse.\n",
                "Cependant, **c'Ã©tait long et verbeux**. Il a fallu Ã©crire une fonction spÃ©cifique pour chaque colonne.\n",
                "\n",
                "Dans le prochain notebook, nous verrons comment un **Agent IA** peut faire tout cela pour nous en quelques secondes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_clean.to_csv('clean_sales_data_manual.csv', index=False)\n",
                "print(\"Fichier propre sauvegardÃ© : clean_sales_data_manual.csv\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
