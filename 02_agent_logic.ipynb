{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Modern Data Cleaning : L'Agent IA (The Smart Way)\n",
                "\n",
                "Dans le notebook pr√©c√©dent, nous avons tout fait √† la main. C'√©tait fastidieux.\n",
                "Ici, nous allons construire un **Workflow Agentique** (Human-in-the-loop) pour automatiser le nettoyage.\n",
                "\n",
                "**Le concept :**\n",
                "1. **Analyse** : L'IA scanne le dataset et propose des actions.\n",
                "2. **Validation** : L'humain s√©lectionne les actions pertinentes (Simul√© ici).\n",
                "3. **Ex√©cution** : L'IA g√©n√®re le code Python et l'ex√©cute."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup & Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import google.generativeai as genai\n",
                "import os\n",
                "import json\n",
                "import io\n",
                "from dotenv import load_dotenv\n",
                "import tabulate\n",
                "\n",
                "# Nouveaut√© : Pydantic pour structurer la sortie\n",
                "from pydantic import BaseModel, Field\n",
                "from typing import List\n",
                "\n",
                "# 1. Chargement des cl√©s\n",
                "load_dotenv()\n",
                "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
                "\n",
                "# 2. Config Gemini\n",
                "genai.configure(api_key=api_key)\n",
                "model = genai.GenerativeModel('gemini-2.5-pro')\n",
                "\n",
                "# 3. Chargement Data\n",
                "df = pd.read_csv('dirty_sales_data.csv')\n",
                "print(\"Donn√©es charg√©es :\", df.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#buffer va permetter de transformer le .info en une string exploitable\n",
                "buffer = io.StringIO()\n",
                "df.info(buf=buffer)\n",
                "info_str = buffer.getvalue()\n",
                "print(info_str)\n",
                "head_str = df.head(20).to_markdown()\n",
                "print(head_str)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Phase 1 : Analyse Automatique\n",
                "\n",
                "Nous avons deux fa√ßons de demander √† l'IA :"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Approche V1 : La m√©thode na√Øve (Texte libre)\n",
                "On demande simplement : \"Analyse √ßa\"."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "prompt_v1 = f\"\"\"\n",
                "Tu es un Data Analyst. Analyse ce dataset (info et head) et dis-moi ce qui ne va pas.\n",
                "Sois concis.\n",
                "\n",
                "DATA INFO:\n",
                "{info_str}\n",
                "\n",
                "DATA HEAD (Markdown):\n",
                "{head_str}\n",
                "\"\"\"\n",
                "\n",
                "print(prompt_v1)\n",
                "\n",
                "response_v1 = model.generate_content(prompt_v1)\n",
                "print(response_v1.text)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(response_v1.text)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                " **Probl√®me** : C'est tr√®s lisible pour un humain, mais **impossible √† utiliser dans une application** (comment cr√©er des checkbox automatiquement √† partir de ce texte ?)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Approche V2 : La m√©thode industrielle (Structured Output)\n",
                "On va d√©finir un **Sch√©ma de donn√©es** rigoureux avec `Pydantic` et forcer l'IA √† le respecter.\n",
                "C'est la m√©thode \"Structured Output\"."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# D√©finition de la structure attendue\n",
                "class DataIssue(BaseModel):\n",
                "    column: str = Field(..., description=\"Nom de la colonne concern√©e\")\n",
                "    issue_type: str = Field(..., description=\"Type de probl√®me (ex: 'Format', 'Duplicata', 'Valeur manquante')\")\n",
                "    description: str = Field(..., description=\"Explication courte du probl√®me\")\n",
                "    suggested_action: str = Field(..., description=\"Action Python sugg√©r√©e (ex: 'pd.to_datetime', 'drop_duplicates')\")\n",
                "\n",
                "class DataAudit(BaseModel):\n",
                "    issues: List[DataIssue]\n",
                "\n",
                "# Appel √† Gemini avec le sch√©ma\n",
                "prompt_v2 = f\"\"\"\n",
                "Analyse ce dataset pour d√©tecter les anomalies de qualit√© (types, doublons, formats).\n",
                "Remplis la structure JSON demand√©e.\n",
                "\n",
                "DATA INFO:\n",
                "{info_str}\n",
                "\n",
                "DATA HEAD:\n",
                "{head_str}\n",
                "\"\"\"\n",
                "\n",
                "response_v2 = model.generate_content(\n",
                "    prompt_v2,\n",
                "    generation_config={\"response_mime_type\": \"application/json\", \"response_schema\": DataAudit}\n",
                ")\n",
                "\n",
                "# Parsing automatique\n",
                "audit_result = json.loads(response_v2.text)\n",
                "print(audit_result)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "issues_list = audit_result['issues']\n",
                "# Affichage utilisable par le code\n",
                "pd.DataFrame(issues_list)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                " **Succ√®s** : Nous avons maintenant une liste d'objets structur√©s que notre interface pourra manipuler."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Phase 2 : Simulation \"Human-in-the-loop\"\n",
                "\n",
                "Dans l'app finale, l'utilisateur validera ces suggestions.\n",
                "Ici, on garde tout."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "selected_actions = issues_list\n",
                "print(f\"Validation simul√©e de {len(selected_actions)} actions.\")\n",
                "\n",
                "selected_actions_restricted = selected_actions[0:3]\n",
                "print(f\"Validation simul√©e de {len(selected_actions_restricted)} actions.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "selected_actions\n",
                "selected_actions_restricted"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Phase 3 : G√©n√©ration & Ex√©cution du Code\n",
                "\n",
                "Derni√®re √©tape : transformer ces instructions JSON en code Python ex√©cutable."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# D√©finition de la structure de sortie pour le code\n",
                "class CodeOutput(BaseModel):\n",
                "    python_script: str = Field(..., description=\"Le script Python complet et ex√©cutable, sans blocs markdown.\")\n",
                "\n",
                "def generate_cleaning_code(df_sample, actions):\n",
                "    cols_context = df_sample.dtypes.to_dict()\n",
                "    \n",
                "    prompt_code = f\"\"\"\n",
                "    Tu es un d√©veloppeur Python Senior.\n",
                "    G√©n√®re le code Python pour nettoyer le dataframe 'df' selon ces actions :\n",
                "    {json.dumps(actions, indent=2)}\n",
                "    df : {df_sample.head(10)}\n",
                "    Colonnes : {cols_context}\n",
                "    \n",
                "    R√®gles :\n",
                "    1. Code ex√©cutable directement sur 'df'\n",
                "    2. G√®re les conversions avec robustesse.\n",
                "    \"\"\"\n",
                "    \n",
                "    # On force une sortie structur√©e contenant le code\n",
                "    response = model.generate_content(\n",
                "        prompt_code,\n",
                "        generation_config={\"response_mime_type\": \"application/json\", \"response_schema\": CodeOutput}\n",
                "    )\n",
                "    \n",
                "    # On r√©cup√®re proprement le script dans le JSON\n",
                "    return json.loads(response.text)['python_script']\n",
                "\n",
                "cleaning_code = generate_cleaning_code(df, selected_actions)\n",
                "print(cleaning_code)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cleaning_code_restricted = generate_cleaning_code(df, selected_actions_restricted)\n",
                "print(cleaning_code_restricted)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Ex√©cution s√©curis√©e (Scope local)\n",
                "df_clean_agent = df.copy()\n",
                "local_scope = {'df': df_clean_agent, 'pd': pd}\n",
                "\n",
                "exec(cleaning_code, {}, local_scope)\n",
                "\n",
                "df_final = local_scope['df']\n",
                "df_final.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Ex√©cution s√©curis√©e (Scope local)\n",
                "df_clean_agent_restricted = df.copy()\n",
                "local_scope_restricted = {'df': df_clean_agent_restricted, 'pd': pd}\n",
                "\n",
                "exec(cleaning_code_restricted, {}, local_scope_restricted)\n",
                "\n",
                "df_final_restricted = local_scope_restricted['df']\n",
                "df_final_restricted.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Le Grand Final : Tout en une fois !\n",
                "Voici le script complet qui encha√Æne tout : Analyse Robuste -> G√©n√©ration Code -> Ex√©cution."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === 1. ANALYSE ROBUSTE ===\n",
                "\n",
                "# Prompt optimis√© pour pousser l'IA dans ses retranchements\n",
                "prompt_robust_audit = f\"\"\"\n",
                "Tu es un Expert Data Engineer impitoyable sur la qualit√© de donn√©es.\n",
                "Audite ce dataset pour produire un plan de nettoyage en b√©ton.\n",
                "\n",
                "DATA HEAD:\n",
                "{head_str}\n",
                "\n",
                "DATA INFO:\n",
                "{info_str}\n",
                "\n",
                "Instructions de nettoyage :\n",
                "1. STANDARDISATION : Unifie la casse des textes (ex: Noms en Title Case, Cat√©gories en minuscule...).\n",
                "2. NETTOYAGE ROBUSTE : Pour les prix, utilise des Regex qui capturent tout (chiffres et s√©parateurs) et virent le reste.\n",
                "3. LOGIQUE M√âTIER : D√©tecte les anomalies s√©mantiques (Quantit√©s n√©gatives ? Doublons d'ID ?).\n",
                "4. DATES : Sois capable de parser des formats mixtes.\n",
                "\n",
                "Retourne une liste structured (JSON) des actions √† mener.\n",
                "\"\"\"\n",
                "\n",
                "print(\"üîç Analyse approfondie en cours...\")\n",
                "response_audit = model.generate_content(\n",
                "    prompt_robust_audit,\n",
                "    generation_config={\"response_mime_type\": \"application/json\", \"response_schema\": DataAudit}\n",
                ")\n",
                "robust_issues = json.loads(response_audit.text)['issues']\n",
                "print(f\" {len(robust_issues)} probl√®mes d√©tect√©s.\")\n",
                "\n",
                "\n",
                "# === 2. GENERATION CODE ===\n",
                "print(\" G√©n√©ration du code de r√©paration...\")\n",
                "robust_code = generate_cleaning_code(df, robust_issues)\n",
                "print(\"Code g√©n√©r√© :\")\n",
                "print(robust_code)\n",
                "\n",
                "\n",
                "# === 3. EXECUTION ===\n",
                "print(\" Ex√©cution...\")\n",
                "df_clean_final = df.copy()\n",
                "scope = {'df': df_clean_final, 'pd': pd}\n",
                "\n",
                "try:\n",
                "    exec(robust_code, {}, scope)\n",
                "    df_final_result = scope['df']\n",
                "    print(\"üéâ Termin√© ! Aper√ßu avant/apr√®s :\")\n",
                "    display(df.head(3))\n",
                "    display(df_final_result.head(3))\n",
                "    print(df_final_result.info())\n",
                "except Exception as e:\n",
                "    print(\" Erreur ex√©cution :\", e)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python (Projet Avis Stores)",
            "language": "python",
            "name": "python_shared_env"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
